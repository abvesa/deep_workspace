{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6590]])\n",
      "tensor([[0.]])\n",
      "tensor([[0.4170]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss_fn = torch.nn.BCELoss(reduce=False, size_average=False)\n",
    "input = Variable(torch.randn(1, 1))\n",
    "target = Variable(torch.FloatTensor(1, 1).random_(2))\n",
    "loss = loss_fn(F.sigmoid(input), target)\n",
    "print(input); print(target); print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FF_NN(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.linear1 = nn.Linear(hidden_size, hidden_size/2)\n",
    "        self.linear2 = nn.Linear(hidden_size/2, hidden_size/8)\n",
    "        self.linear3 = nn.Linear(hidden_size/8, 1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.linear1(input)\n",
    "        output = self.linear2(output)\n",
    "        output = self.linear3(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D_RNN(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(D_RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(1, hidden_size)   \n",
    "            \n",
    "    def forward(self, input, hidden):        \n",
    "        output, hidden = self.gru(input, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G_RNN(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.gru = nn.GRU(1, hidden_size)\n",
    "        \n",
    "        self.linear1 = nn.Linear(hidden_size, hidden_size/2)\n",
    "        self.linear2 = nn.Linear(hidden_size/2, hidden_size/8)\n",
    "        self.linear3 = nn.Linear(hidden_size/8, 1)\n",
    "\n",
    "    def forward(self, input, hidden):  \n",
    "        output, hidden = self.gru(input, hidden)\n",
    "        output = self.linear1(output)\n",
    "        output = self.linear2(output)\n",
    "        output = self.linear3(output)\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.randn(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "    def initInput(self):\n",
    "        return torch.rand(1, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full((1,), 1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(netD, netG, clsLayer, netD_opt, netG_opt, clsLayer_opt, criterion):\n",
    "    ### update discriminator ###\n",
    "    # (1) train with real data # \n",
    "    \n",
    "    netD.zero_grad()\n",
    "    clsLayer.zero_grad()\n",
    "    \n",
    "    netD_hidden = netD.initHidden()\n",
    "    random_tensor = torch.rand(1, 1, seq_length)\n",
    "    label = torch.full((1,), 1, device=device)\n",
    "    \n",
    "    # pass real data through discriminator\n",
    "    for i in range(seq_length):\n",
    "        netD_output, netD_hidden = netD(random_tensor[i], netD_hidden)\n",
    "    \n",
    "    real_output = clsLayer(netD_hidden).view(-1)\n",
    "    errD_real = criterion(real_output, label)\n",
    "    errD_real.backward()\n",
    "    \n",
    "    # (2) train with fake data #\n",
    "    \n",
    "    netG_hidden = netG.initHidden()\n",
    "    netG_input = netG.initInput()\n",
    "    label.fill_(0)\n",
    "    \n",
    "    # generate fake data through generator\n",
    "    netG_fake = torch.zeros(seg_length, 1, device=device)\n",
    "    for i in range(seq_length):\n",
    "        netG_input, netG_hidden = netG(netG_input, netG_hidden)\n",
    "        netG_fake[i] = netG_input[0, 0]\n",
    "        \n",
    "    # pass fake data through discriminator\n",
    "    netD_hidden = netD.initHidden()\n",
    "    for i in range(seq_length):\n",
    "        netD_output, netD_hidden = netD(netG_fake[i].detach(), netD_hidden)\n",
    "        \n",
    "    fake_output = clsLayer(netD_hidden).view(-1)\n",
    "    errD_fake = criterion(fake_output, label)\n",
    "    errD_fake.backward()\n",
    "    \n",
    "    # update discriminator graident\n",
    "    netD_opt.step()\n",
    "    ######\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### update generator ###\n",
    "    netG.zero_grad()\n",
    "    label.fill_(1)\n",
    "    \n",
    "    # train generator to make fake data become real\n",
    "    netD_hidden = netD.initHidden()\n",
    "    for i in range(seq_length):\n",
    "        netD_output, netD_hidden = netD(netG_fake[i], netD_hidden)\n",
    "        \n",
    "    output = clsLayer(netD_hidden).view(-1)\n",
    "    errG = criterion(output, label)\n",
    "    errG.backward()\n",
    "    \n",
    "    netG_opt.step()\n",
    "    ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py367",
   "language": "python",
   "name": "py367"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
